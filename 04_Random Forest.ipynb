{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install IPython\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Seung-hwanSong/Tree.git #코랩 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [의사결정나무 및 앙상블 Part 1]\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### jupyter notebook 단축키\n",
    "\n",
    "- ctrl+enter: 셀 실행   \n",
    "- shift+enter: 셀 실행 및 다음 셀 이동   \n",
    "- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n",
    "- a: 상단에 새로운 셀 만들기\n",
    "- b: 하단에 새로운 셀 만들기\n",
    "- dd: 셀 삭제(x: 셀 삭제)\n",
    "- 함수 ( ) 안에서 shift+tab: arguments description. shift+tab+tab은 길게 볼 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 배깅(Bagging) 이란?\n",
    "### 배깅(Bagging)은 Bootstrap Aggregating의 약자로, 동일한 알고리즘으로 여러 분류기를 만들고 보팅(Voting)으로 최종 결정하는 알고리즘\n",
    "\n",
    "### ** 배깅은 다음과 같은 방식으로 진행이 됩니다.\n",
    "\n",
    "(1) 동일한 알고리즘을 사용하는 일정 수의 분류기 생성\n",
    "\n",
    "(2)각각의 분류기는 부트스트래핑(Bootstrapping)방식으로 생성된 샘플데이터를 학습\n",
    "\n",
    "(3)최종적으로 모든 분류기가 보팅을 통헤 예측 결정\n",
    "\n",
    "※ 부트스트래핑 샘플링은 전체 데이터에서 일부 데이터의 중첩을 허용하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/Tree/image/intro1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤포레스트(RandomForest)\n",
    "### 랜덤 포레스트는 여러 개의 결정트리(Decision Tree)를 활용한 배깅 방식의 대표적인 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/Tree/image/intro2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 데이터 전처리 \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" 모델 생성, 학습, 평가 \"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분석 데이터 : Otto Group Product Classification Challenge Dataset (kaggle data)\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/data?select=train.csv\n",
    "\n",
    "### 설명변수 (X)\n",
    "#### - id\n",
    "#### - feat_1 ~ feat_93\n",
    "\n",
    "### 반응변수 (Y)\n",
    "#### - Class_1 ~ Class_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (kaggle data)\n",
    "data = pd.read_csv('/content/Tree/data/otto_train.csv')\n",
    "# data = pd.read_csv(\"./data/otto_train.csv\") #로컬\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape확인\n",
    "\n",
    "nCar = data.shape[0] # 데이터 개수\n",
    "nVar = data.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무의미한 변수 제거\n",
    "\n",
    "data= data.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수의 형변환\n",
    "\n",
    "mapping_dict = {'Class_1' : 1,\n",
    "                'Class_2' : 2,\n",
    "                'Class_3' : 3,\n",
    "                'Class_4' : 4,\n",
    "                'Class_5' : 5,\n",
    "                'Class_6' : 6,\n",
    "                'Class_7' : 7,\n",
    "                'Class_8' : 8,\n",
    "                'Class_9' : 9,}\n",
    "after_mapping_target = data['target'].apply(lambda x : mapping_dict[x])\n",
    "after_mapping_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features/target, train/test dataset 분리\n",
    "\n",
    "feature_columns = list(data.columns.difference(['target']))\n",
    "X = data[feature_columns]\n",
    "y = after_mapping_target\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 2024) # 학습데이터와 평가데이터의 비율을 8:2 로 분할| \n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/Tree/image/intro3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) Gini Index 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본적인 randomforest모형\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=20, max_depth=5, criterion='gini',random_state=2024)\n",
    "clf1.fit(train_x,train_y)\n",
    "\n",
    "predict1 = clf1.predict(test_x)\n",
    "acc1 = accuracy_score(test_y,predict1)\n",
    "print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Sample개수 증가\n",
    "# sample 100개, tree depth - 20\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=100, max_depth=20, criterion='gini', random_state=2024)\n",
    "clf2.fit(train_x,train_y)\n",
    "\n",
    "predict2 = clf2.predict(test_x)\n",
    "acc2 = accuracy_score(test_y,predict2)\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 300개, tree depth - 20\n",
    "\n",
    "clf3 = RandomForestClassifier(n_estimators=300, max_depth=20, criterion='gini', random_state=2024)\n",
    "clf3.fit(train_x,train_y)\n",
    "\n",
    "predict3 = clf3.predict(test_x)\n",
    "acc3 = accuracy_score(test_y,predict3)\n",
    "print(acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Tree 깊이 증가\n",
    "# sample 100개, tree depth - 100(max)\n",
    "\n",
    "clf4 = RandomForestClassifier(n_estimators=100, max_depth=100, criterion='gini', random_state=2024)\n",
    "clf4.fit(train_x,train_y)\n",
    "\n",
    "predict4 = clf4.predict(test_x)\n",
    "acc4 = accuracy_score(test_y,predict4)\n",
    "print(acc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) Entropy 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본적인 randomforest모형\n",
    "\n",
    "clf5 = RandomForestClassifier(n_estimators=20, max_depth=5, criterion='entropy',random_state=2024)\n",
    "clf5.fit(train_x,train_y)\n",
    "\n",
    "predict5 = clf5.predict(test_x)\n",
    "acc5 = accuracy_score(test_y,predict5)\n",
    "print(acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Sample개수 증가\n",
    "# sample 100개, tree depth - 20\n",
    "\n",
    "clf6 = RandomForestClassifier(n_estimators=100, max_depth=20, criterion='entropy', random_state=2024)\n",
    "clf6.fit(train_x,train_y)\n",
    "\n",
    "predict6 = clf6.predict(test_x)\n",
    "acc6 = accuracy_score(test_y,predict6)\n",
    "print(acc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 300개, tree depth - 20\n",
    "\n",
    "clf7 = RandomForestClassifier(n_estimators=300, max_depth=20, criterion='entropy', random_state=2024)\n",
    "clf7.fit(train_x,train_y)\n",
    "\n",
    "predict7 = clf7.predict(test_x)\n",
    "acc7 = accuracy_score(test_y,predict7)\n",
    "print(acc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Tree 깊이 증가\n",
    "# sample 100개, tree depth - 100(max)\n",
    "\n",
    "clf8 = RandomForestClassifier(n_estimators=100, max_depth=100, criterion='entropy', random_state=2024)\n",
    "clf8.fit(train_x,train_y)\n",
    "\n",
    "predict8 = clf8.predict(test_x)\n",
    "acc8 = accuracy_score(test_y,predict8)\n",
    "print(acc8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "acc_summary = {'Gini Index':[acc1, acc2, acc3, acc4],\n",
    "               'Entropy':[acc5, acc6, acc7, acc8]}\n",
    "\n",
    "acc_summary = pd.DataFrame(acc_summary)\n",
    "acc_summary.index=['Sample: 20, Depth:  5', 'Sample:100, Depth: 20', 'Sample:300, Depth: 20', 'Sample:100, Depth:100']\n",
    "print(acc_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) Grid Serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [10, 20, 100, 300],\n",
    "           'max_depth' : [5, 10, 20, 100],\n",
    "           'criterion' : ['entropy', 'gini']\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "clf9 = RandomForestClassifier(random_state = 2024, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(clf9, param_grid = params, cv = 3, n_jobs = -1)\n",
    "grid_cv.fit(train_x, train_y)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf10 = RandomForestClassifier(n_estimators = ?, \n",
    "                                max_depth = ?,\n",
    "                                criterion = '?',\n",
    "                                random_state = 2024,\n",
    "                                n_jobs = -1)\n",
    "\n",
    "# clf10 = RandomForestClassifier(n_estimators = 100, \n",
    "#                                 max_depth = 12,\n",
    "#                                 min_samples_leaf = 8,\n",
    "#                                 min_samples_split = 8,\n",
    "#                                 random_state = 1,\n",
    "#                                 n_jobs = -1)\n",
    "clf10.fit(train_x, train_y)\n",
    "predict10 = clf10.predict(test_x)\n",
    "print('예측 정확도: {:.4f}'.format(accuracy_score(test_y,predict10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttest3.8",
   "language": "python",
   "name": "ttest3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
